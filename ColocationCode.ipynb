{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0aCuJPIbu8kkmjSJ1B0Yc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnRuskinONLINE/epic-classification/blob/master/ColocationCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentinel Satellite (2 and 3) Co-location and Unsupervised Machine Learning**"
      ],
      "metadata": {
        "id": "4yEkAcsuc0Yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of code details the co-locating aspect of the code. It is split into annotated chunks to make the running of it less RAM intensive, and to allow the pinpointing of errors, if and when they may occur, easier."
      ],
      "metadata": {
        "id": "lbyOoD1bdAu4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PYA2V5AOYm5"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "#      _   ____     ___   #\n",
        "#     | | |  _ \\   / _ \\  #\n",
        "#  _  | | | |_) | | | | | #\n",
        "# | |_| | |  _ <  | |_| | #\n",
        "#  \\___/  |_| \\_\\  \\___/  #\n",
        "#                         #\n",
        "###########################\n",
        "\n",
        "########################################################################################################\n",
        "# Mount your Google Drive, it is important that you use one acccount consistently. the likewise details#\n",
        "# for Earth Engine, Colab, etcetera. You will also require an account for the Copernicus Space         #\n",
        "# Database, for this I reccomend that you use a novel password as I have done on line XX, to reduce any#\n",
        "# possible security risks associated with sharing this code with colleagues, friends, etc.             #\n",
        "########################################################################################################\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Import and install if neccesary (!pip install package) your packages\n",
        "\n",
        "import ee\n",
        "from datetime import datetime, timedelta\n",
        "from shapely.geometry import Polygon, Point\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "########################################################################################################\n",
        "# Here we connect Google Colab to Google Earth Engine, Earth Engine will be used to retrieve our       #\n",
        "# satellite date. Make SURE that you enable the 'Earth Engine' API within the Google Earth Engine.     #\n",
        "# Change 'week4datasdn' to a unique identifier of your choice. It does not particularly matter what,   #\n",
        "# it is just a means for interfacing.                                                                  #\n",
        "########################################################################################################\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='week4fetchdatasdn')\n",
        "def get_matched_S2_image_ids(s3_image,boundary_geometry):\n",
        "        s3_time = datetime.utcfromtimestamp(s3_image.get('system:time_start').getInfo() / 1000)\n",
        "\n",
        "        # Define a time window for S2 search (Â±3 hours from S3 image time)\n",
        "        start_time = s3_time - timedelta(hours=3)\n",
        "        end_time = s3_time + timedelta(hours=3)\n",
        "\n",
        "        # Query for S2 images within the time window and spatial extent of S3\n",
        "        S2_collection = ee.ImageCollection('COPERNICUS/S2') \\\n",
        "        .filterDate(start_time, end_time) \\\n",
        "        .filterBounds(boundary_geometry)\n",
        "\n",
        "        # Return the list of S2 image IDs\n",
        "        return S2_collection.aggregate_array('system:index').getInfo()\n",
        "\n",
        "########################################################################################################\n",
        "# Below is a function to find matched Sentinel02 image IDs for each Sentinel03 image in the given date #\n",
        "# and spacial extent defined by the previous function                                                  #\n",
        "########################################################################################################\n",
        "\n",
        "def find_matched_satellite_images(S3_date_range, S3_spatial_extent, boundary_geometry):\n",
        "\n",
        "    # Define variables for Sentinel-3 query\n",
        "    S3_product = 'COPERNICUS/S3/OLCI'\n",
        "\n",
        "    # Query for Sentinel-3 data, again utilising Earth Engine\n",
        "    S3_collection = ee.ImageCollection(S3_product) \\\n",
        "        .filterDate(S3_date_range[0], S3_date_range[1]) \\\n",
        "        .filterBounds(boundary_geometry)\n",
        "\n",
        "    # Convert S3_collection to a list of image IDs\n",
        "    S3_image_ids = S3_collection.aggregate_array('system:index').getInfo()\n",
        "\n",
        "    # List to store matched pairs\n",
        "    matched_pairs = []\n",
        "\n",
        "    # Loop through each S3 image ID and find matching S2 images\n",
        "    for s3_image_id in S3_image_ids:\n",
        "        s3_image = ee.Image(S3_collection.filter(ee.Filter.eq('system:index', s3_image_id)).first())\n",
        "        matched_S2_image_ids = get_matched_S2_image_ids(s3_image,boundary_geometry)\n",
        "\n",
        "        # Record each pair of matched S3 and S2 images\n",
        "        for s2_image_id in matched_S2_image_ids:\n",
        "            matched_pairs.append((s3_image_id, s2_image_id))\n",
        "\n",
        "    return matched_pairs\n",
        "\n",
        "########################################################################################################\n",
        "# Parses the Google Earth Engine filename to extract satellite name, sensing date, and start time.     #\n",
        "# Parameters:                                                                                          #\n",
        "# gee_filename (str): Filename obtained from Google Earth Engine.                                      #\n",
        "#                                                                                                      #\n",
        "# Returns:                                                                                             #\n",
        "# tuple: Contains satellite name, sensing date, and start time.                                        #\n",
        "########################################################################################################\n",
        "\n",
        "def parse_gee_filename(gee_filename):\n",
        "    parts = gee_filename.split('_')\n",
        "    sensing_date = parts[0]\n",
        "    tile_number = parts[2]\n",
        "    return sensing_date, tile_number\n",
        "\n",
        "def parse_gee_filename_s3(gee_filename):\n",
        "    parts = gee_filename.split('_')\n",
        "    satellite = parts[0] + '_OL_1_EFR'\n",
        "    start_datetime = parts[1]\n",
        "    end_datetime = parts[2]\n",
        "\n",
        "    # Extract date from the start_datetime (assuming the format is like '20180601T014926')\n",
        "    sensing_date = start_datetime[:8]\n",
        "    start_time = start_datetime[9:]\n",
        "\n",
        "    return satellite, sensing_date, start_time\n",
        "\n",
        "########################################################################################################\n",
        "# Retrieves access token from Copernicus Dataspace using the provided credentials.                     #\n",
        "#                                                                                                      #\n",
        "# Parameters:                                                                                          #\n",
        "# username (str): Username for Copernicus Dataspace.                                                   #\n",
        "# password (str): Password for Copernicus Dataspace.                                                   #\n",
        "#                                                                                                      #\n",
        "# Returns:                                                                                             #\n",
        "# str: Access token for authenticated sessions.                                                        #\n",
        "#                                                                                                      #\n",
        "# These elements do not need to be changed YET. Here functions are simply being defined.               #\n",
        "########################################################################################################\n",
        "\n",
        "def get_access_token(username, password):\n",
        "    url = 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token'\n",
        "    data = {\n",
        "        'grant_type': 'password',\n",
        "        'username': username,\n",
        "        'password': password,\n",
        "        'client_id': 'cdse-public'\n",
        "    }\n",
        "    response = requests.post(url, data=data)\n",
        "    response.raise_for_status()\n",
        "    return response.json()['access_token']\n",
        "\n",
        "########################################################################################################\n",
        "# Queries the Sentinel-2 data from the Copernicus Data Space based on sensing start date, tile number, #\n",
        "# and access token.                                                                                    #\n",
        "#                                                                                                      #\n",
        "# Parameters:                                                                                          #\n",
        "# sensing_start_date(str): The start date and time for the data sensing in the format 'YYYYMMDDTHHMMSS'#\n",
        "# tile_number (str): The specific tile number of the Sentinel-2 data to be queried.                    #\n",
        "# token (str): The access token for authenticating requests to the Copernicus Data Space.              #\n",
        "#                                                                                                      #\n",
        "# Returns:                                                                                             #\n",
        "# DataFrame: A DataFrame containing the query results with details about the Sentinel-2 data.          #\n",
        "#                                                                                                      #\n",
        "# The function constructs a query URL with specified parameters, sends a request to the Copernicus Data#\n",
        "# Space, and returns the results as a DataFrame. It filters the data based on the tile number and the  #\n",
        "#content start date within a certain time window.                                                      #\n",
        "########################################################################################################\n",
        "\n",
        "def query_sentinel2_data(sensing_start_date, tile_number, token):\n",
        "\n",
        "    # Convert sensing_start_date to datetime object and format it for the query\n",
        "    start_time = datetime.strptime(sensing_start_date, '%Y%m%dT%H%M%S')\n",
        "    end_time = start_time + timedelta(hours=2)  # Adjust the time window as necessary\n",
        "    start_time_str = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "    end_time_str = end_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "\n",
        "    # Construct the request URL with the contains function for tile number\n",
        "    url = f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'{tile_number}') and Collection/Name eq 'SENTINEL-2' and ContentDate/Start gt {start_time_str} and ContentDate/Start lt {end_time_str}\"\n",
        "    headers = {'Authorization': f'Bearer {token}'}\n",
        "\n",
        "    # Make the API request\n",
        "    response = requests.get(url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    return pd.DataFrame.from_dict(response.json()['value'])\n",
        "\n",
        "########################################################################################################\n",
        "# Extracts the correct product name and ID from a dataframe based on a specific start time and tile    #\n",
        "# number.                                                                                              #\n",
        "#                                                                                                      #\n",
        "# Parameters:                                                                                          #\n",
        "# df (DataFrame): The dataframe containing product information.                                        #\n",
        "# start_time (str): The start time used to filter the products.                                        #\n",
        "#  tile_number (str): The tile number used to filter the products.                                     #\n",
        "#                                                                                                      #\n",
        "# Returns:                                                                                             #\n",
        "# tuple: A tuple containing the first matching product name and ID, or (None, None) if no match is     #\n",
        "# found.                                                                                               #\n",
        "########################################################################################################\n",
        "\n",
        "def extract_correct_product_name(df, start_time, tile_number):\n",
        "\n",
        "    # Adjusted regex pattern to match the filename format\n",
        "    pattern = f'MSIL1C.*{start_time}.*_{tile_number}_'\n",
        "    filtered_products = df[df['Name'].str.contains(pattern, regex=True)]\n",
        "\n",
        "    # Return the first matching product name, or None if not found\n",
        "    return filtered_products['Name'].iloc[0] if not filtered_products.empty else None, filtered_products['Id'].iloc[0] if not filtered_products.empty else None\n",
        "\n",
        "########################################################################################################\n",
        "# Processes a pair of Sentinel-2 images by querying the Copernicus Data Space to find the corresponding#\n",
        "#product name and ID.                                                                                  #\n",
        "#                                                                                                      #\n",
        "# Parameters:                                                                                          #\n",
        "# s2_ee_image_id (str): The Sentinel-2 Earth Engine image ID.                                          #\n",
        "# token (str): The access token for authenticating requests to the Copernicus Data Space.              #\n",
        "#                                                                                                      #\n",
        "# Returns:                                                                                             #\n",
        "# tuple: A tuple containing the product name and ID for the corresponding Sentinel-2 image.            #\n",
        "########################################################################################################\n",
        "\n",
        "def process_image_pair(s2_ee_image_id, token):\n",
        "\n",
        "    sensing_start_date = s2_ee_image_id.split('_')[0]\n",
        "    tile_number = s2_ee_image_id.split('_')[2]\n",
        "\n",
        "    # Query the Copernicus Data Space\n",
        "    df = query_sentinel2_data(sensing_start_date, tile_number, token)\n",
        "\n",
        "    # Extract the correct MSIL1C product name\n",
        "    return extract_correct_product_name(df, sensing_start_date, tile_number)\n",
        "\n",
        "########################################################################################################\n",
        "# Download a single product from the Copernicus Data Space.                                            #\n",
        "#                                                                                                      #\n",
        "# Parameters:                                                                                          #\n",
        "# product_id: The unique identifier for the product.                                                   #\n",
        "# file_name: The name of the file to be downloaded.                                                    #\n",
        "# access_token: The access token for authorization.                                                    #\n",
        "# download_dir: The directory where the product will be saved.                                         #\n",
        "########################################################################################################\n",
        "\n",
        "def download_single_product(product_id, file_name, access_token, download_dir=\"downloaded_products\"):\n",
        "\n",
        "    # Ensure the download directory exists\n",
        "    os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "    # Construct the download URL\n",
        "    url = f\"https://zipper.dataspace.copernicus.eu/odata/v1/Products({product_id})/$value\"\n",
        "\n",
        "    # Set up the session and headers\n",
        "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "    session = requests.Session()\n",
        "    session.headers.update(headers)\n",
        "\n",
        "    # Perform the request\n",
        "    response = session.get(url, headers=headers, stream=True)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Define the path for the output file\n",
        "        output_file_path = os.path.join(download_dir, file_name + \".zip\")\n",
        "\n",
        "        # Stream the content to a file\n",
        "        with open(output_file_path, \"wb\") as file:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "        print(f\"Downloaded: {output_file_path}\")\n",
        "    else:\n",
        "        print(f\"Failed to download product {product_id}. Status Code: {response.status_code}\")\n",
        "\n",
        "########################################################################################################\n",
        "# Queries Sentinel-3 OLCI data from Copernicus Data Space based on satellite name, sensing date,       #\n",
        "# and start time.                                                                                      #\n",
        "#                                                                                                      #\n",
        "# Parameters:                                                                                          #\n",
        "# satellite (str): Name of the satellite.                                                              #\n",
        "# sensing_date (str): Date of the data sensing.                                                        #\n",
        "# start_time (str): Start time of the data sensing.                                                    #\n",
        "# token (str): Access token for authentication.                                                        #\n",
        "#                                                                                                      #\n",
        "# Returns:                                                                                             #\n",
        "# DataFrame: A DataFrame containing the query results with details about the Sentinel-3 OLCI data.     #\n",
        "########################################################################################################\n",
        "\n",
        "def query_sentinel3_olci_data(satellite, sensing_date, start_time, token):\n",
        "\n",
        "    # Convert sensing_date to datetime object and format it for the query\n",
        "    sensing_datetime = datetime.strptime(f'{sensing_date}T{start_time}', '%Y%m%dT%H%M%S')\n",
        "    sensing_datetime = sensing_datetime - timedelta(seconds=1)\n",
        "\n",
        "    # Construct the request URL using the filter structure provided\n",
        "    url = (\n",
        "        f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?\"\n",
        "        f\"$filter=contains(Name,'{satellite}') and \"\n",
        "        f\"ContentDate/Start ge {sensing_datetime.strftime('%Y-%m-%dT%H:%M:%S.000Z')} and \"\n",
        "        f\"ContentDate/Start le {(sensing_datetime + timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%S.000Z')}&\"\n",
        "        f\"$orderby=ContentDate/Start&$top=1000\"\n",
        "    )\n",
        "    headers = {'Authorization': f'Bearer {token}'}\n",
        "\n",
        "    # Print the URL for debugging\n",
        "    print(url)\n",
        "\n",
        "    # Make the API request\n",
        "    response = requests.get(url, headers=headers)\n",
        "    # Check if the request was successful\n",
        "    if response.status_code != 200:\n",
        "        # Print error details and return an empty DataFrame if the request failed\n",
        "        print(f\"Error: Unable to fetch data. Status Code: {response.status_code}. Response: {response.text}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Convert the JSON response to a DataFrame\n",
        "    search_results_df = pd.DataFrame.from_dict(response.json()['value'])\n",
        "\n",
        "    # Convert the 'ContentDate/Start' to datetime objects and sort the results\n",
        "    search_results_df['SensingStart'] = pd.to_datetime(search_results_df['ContentDate'].apply(lambda x: x['Start']))\n",
        "    search_results_df.sort_values(by='SensingStart', inplace=True)\n",
        "\n",
        "    return search_results_df\n",
        "\n",
        "########################################################################################################\n",
        "# Fetches Sentinel-3 OLCI images based on a specified date range and area of interest.                 #\n",
        "#                                                                                                      #\n",
        "# Parameters:                                                                                          #\n",
        "# date_range: List containing the start and end dates (e.g., ['2018-06-01', '2018-06-02'])             #\n",
        "# spatial_extent: List containing the spatial extent [min_lon, min_lat, max_lon, max_lat]              #\n",
        "# area_of_interest: ee.Geometry object defining the specific area for which to fetch images            #\n",
        "#                                                                                                      #\n",
        "# Returns:                                                                                             #\n",
        "# List of dictionaries, each containing details about a fetched image, including its ID,               #\n",
        "# date, and download URL.                                                                              #\n",
        "########################################################################################################\n",
        "\n",
        "def fetch_S3_images_by_area_and_date(date_range, spatial_extent, area_of_interest):\n",
        "\n",
        "    # Initialize the Earth Engine module\n",
        "    ee.Initialize()\n",
        "\n",
        "    # Define variables for Sentinel-3 OLCI query\n",
        "    S3_product = 'COPERNICUS/S3/OLCI'\n",
        "\n",
        "    # Query for Sentinel-3 data within the specified date range and area of interest\n",
        "    S3_collection = ee.ImageCollection(S3_product) \\\n",
        "        .filterDate(date_range[0], date_range[1]) \\\n",
        "        .filterBounds(area_of_interest)\n",
        "\n",
        "    # Convert S3_collection to a list of image IDs\n",
        "    S3_image_ids = S3_collection.aggregate_array('system:index').getInfo()\n",
        "    S3_images_info = S3_collection.getInfo()['features']\n",
        "\n",
        "    # Initialize an empty list to store details\n",
        "    S3_image_details = []\n",
        "\n",
        "    # Iterate through each image in the collection\n",
        "    for img_info in S3_images_info:\n",
        "        # Fetch image ID\n",
        "        image_id = img_info['id']\n",
        "\n",
        "        # Fetch image date and other properties as needed\n",
        "        image_date = img_info['properties']['system:time_start']  # Example property\n",
        "\n",
        "        # Append the details to the list\n",
        "        S3_image_details.append({\n",
        "            'id': image_id,\n",
        "            'date': image_date\n",
        "        })\n",
        "\n",
        "    return S3_image_details\n",
        "\n",
        "########################################################################################################\n",
        "# Retrieves Sentinel-2 images within the Arctic region for a specified date range and cloud coverage   #\n",
        "# limit.                                                                                               #\n",
        "#                                                                                                      #\n",
        "# Parameters:                                                                                          #\n",
        "# start_date (str): The starting date for the image collection in 'YYYY-MM-DD' format.                 #\n",
        "# end_date (str): The ending date for the image collection in 'YYYY-MM-DD' format.                     #\n",
        "# area (ee.Geometry): The geographical area within which to filter the Sentinel-2 images.              #\n",
        "# max_cloud_percentage (float, optional): The maximum cloud coverage percentage for filtering images.  #\n",
        "# Defaults to 10 percent.                                                                              #\n",
        "#                                                                                                      #\n",
        "# Returns:                                                                                             #\n",
        "# ee.ImageCollection: A collection of Sentinel-2 images that fall within the specified date range,     #\n",
        "# cloud coverage limit, and geographical area.                                                         #\n",
        "########################################################################################################\n",
        "\n",
        "def get_s2_images_in_arctic(start_date, end_date, max_cloud_percentage=10):\n",
        "\n",
        "    # Define the Arctic region bounding box\n",
        "    arctic_region = ee.Geometry.Rectangle([-180, 60, 180, 90])\n",
        "\n",
        "    # Filter the Sentinel-2 collection\n",
        "    s2_collection = ee.ImageCollection('COPERNICUS/S2') \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filterBounds(arctic_region) \\\n",
        "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_percentage))\n",
        "\n",
        "    return s2_collection\n",
        "\n",
        "########################################################################################################\n",
        "# Finds Sentinel-3 images that are temporally and spatially colocated with a given Sentinel-2 image.   #\n",
        "#                                                                                                      #\n",
        "# Parameters:                                                                                          #\n",
        "# s2_image (ee.Image): The Sentinel-2 image to use as a reference for finding colocated Sentinel-3     #\n",
        "# images.                                                                                              #\n",
        "# buffer_distance (int, optional): The buffer distance in meters to apply to the footprint of the      #\n",
        "# Sentinel-2 image. Defaults to 10,000 meters.                                                         #\n",
        "# time_window_hours (int, optional): The time window in hours to search for Sentinel-3 images before   #\n",
        "# and after the Sentinel-2 image's acquisition time. Defaults to 2 hours.                              #\n",
        "#                                                                                                      #\n",
        "# Returns:                                                                                             #\n",
        "# ee.List: A list of Sentinel-3 images that are within the specified time window and overlapping       #\n",
        "# the buffered footprint of the provided Sentinel-2 image.                                             #\n",
        "########################################################################################################\n",
        "\n",
        "def find_colocated_s3_for_s2(s2_image, buffer_distance=10000, time_window_hours=2):\n",
        "\n",
        "    # Buffer the S2 footprint and define time window\n",
        "    s2_geometry = s2_image.geometry().buffer(buffer_distance)\n",
        "    s2_time = ee.Date(s2_image.get('system:time_start'))\n",
        "    start_time = s2_time.advance(-time_window_hours, 'hour')\n",
        "    end_time = s2_time.advance(time_window_hours, 'hour')\n",
        "\n",
        "    # Query for S3 images\n",
        "    s3_collection = ee.ImageCollection('COPERNICUS/S3/OLCI') \\\n",
        "        .filterDate(start_time, end_time) \\\n",
        "        .filterBounds(s2_geometry)\n",
        "\n",
        "    return s3_collection.toList(s3_collection.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mn1aLMqNOYm7"
      },
      "outputs": [],
      "source": [
        "########################################################################################################\n",
        "# Co-location Code:                                                                                    #\n",
        "# Once you have set up your environment and are authenticated with Google Earth Engine, the next step  #\n",
        "# is to extract the matched filenames that meet your specific criteria. This involves querying the     #\n",
        "# Google Earth Engine datasets based on your area of interest, time frame, and any other relevant      #\n",
        "# parameters. We will get a list of matched filenames but we only select one of them to download. The  #\n",
        "# code snippet below demonstrates how to perform this task effectively:                                #\n",
        "########################################################################################################\n",
        "\n",
        "#initialise Earth Engine again\n",
        "ee.Initialize()\n",
        "start_date = '2019-03-01'\n",
        "end_date = '2019-03-02'\n",
        "s2_collection = get_s2_images_in_arctic(start_date, end_date)\n",
        "\n",
        "# Iterate over S2 images and find colocated S3 images\n",
        "# Define the empty array matched_pairs\n",
        "matched_pairs = []\n",
        "s2_list = s2_collection.toList(s2_collection.size()).getInfo()\n",
        "for s2_info in s2_list:\n",
        "    s2_image = ee.Image(s2_info['id'])\n",
        "    colocated_s3 = find_colocated_s3_for_s2(s2_image)\n",
        "    s3_info_list = colocated_s3.getInfo()\n",
        "\n",
        "    for s3_info in s3_info_list:\n",
        "        matched_pairs.append((s2_info['id'], s3_info['id']))\n",
        "\n",
        "# Print or process the matched pairs\n",
        "for pair in matched_pairs:\n",
        "    print(\"S2 Image:\", pair[0], \"has colocated S3 Image:\", pair[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hpqFbnPOYm8"
      },
      "outputs": [],
      "source": [
        "########################################################################################################\n",
        "# Here you define the variables you used to define the functions written at the beginning of this code,#\n",
        "# here you should change the email and password to that of your Copernicus Space Database account.     #\n",
        "# change the parameter gee_filename to the sentinel02 filename produced by the previous snippet of     #\n",
        "# code. The parameter download_dir should be set to within your Google Drive.                          #\n",
        "########################################################################################################\n",
        "\n",
        "username = 'zcfbsne@ucl.ac.uk'\n",
        "password = '9XzTbN4!_v_Unqn'\n",
        "\n",
        "token = get_access_token(username, password)\n",
        "access_token = token\n",
        "download_dir = '/content/drive/MyDrive/GEOL0069/Week4'\n",
        "\n",
        "#Sentinel02 filename\n",
        "gee_filename = '20190301T235611_20190301T235610_T01WCM'\n",
        "token = get_access_token(username, password)\n",
        "file_name, product_id = process_image_pair(gee_filename, token)\n",
        "download_single_product(product_id, file_name, access_token, download_dir)\n",
        "print(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_hnoSnHOYm8"
      },
      "outputs": [],
      "source": [
        "########################################################################################################\n",
        "# Here you define the variables you used to define the functions written at the beginning of this code,#\n",
        "# here you should change the email and password to that of your Copernicus Space Database account.     #\n",
        "# Change the parameter gee_filename to the sentinel03 filename produced by the previous snippet of     #\n",
        "# code.                                                                                                #\n",
        "########################################################################################################\n",
        "\n",
        "# Example GEE image ID\n",
        "username = 'zcfbsne@ucl.ac.uk'\n",
        "password = '9XzTbN4!_v_Unqn'\n",
        "token = get_access_token(username, password)\n",
        "gee_image_id = 'S3A_20190301T222350_20190301T222650'\n",
        "# Parse the GEE filename to get the date and time\n",
        "satellite, sensing_date, start_time = parse_gee_filename_s3(gee_image_id)\n",
        "\n",
        "# Query the Copernicus Data Space for the corresponding Sentinel-3 OLCI data\n",
        "s3_olci_data = query_sentinel3_olci_data(satellite, sensing_date, start_time, token)\n",
        "download_dir = '/content/drive/MyDrive/GEOL0069/Week4' # Replace with your desired download directory\n",
        "product_id = s3_olci_data['Id'][0]\n",
        "file_name = s3_olci_data['Name'][0]\n",
        "print(file_name)\n",
        "\n",
        "# Download the single product\n",
        "download_single_product(product_id, file_name, access_token, download_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bjHejMVaeBZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUa_Jh0yOYm9"
      },
      "outputs": [],
      "source": [
        "########################################################################################################\n",
        "# The Sentinel-3 satellite offers an exceptional capability in Earth observation: the simultaneous     #\n",
        "# acquisition of optical data from its OLCI instrument and altimetry measurements. In this section, I  #\n",
        "# will guide you through the process of downloading this colocated altimetry data alongside the        #\n",
        "# Sentinel-3 OLCI optical data.                                                                        #\n",
        "########################################################################################################\n",
        "\n",
        "#Import and install if neccesary (!pip install package) your packages\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import json\n",
        "from datetime import date\n",
        "from joblib import Parallel, delayed\n",
        "import zipfile\n",
        "import sys\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "# Here are defined numerous functions, using variable previous defined, in text delimation describes exactly what they do!\n",
        "\n",
        "#=============================================================================================================================================================#\n",
        "\n",
        "def get_access_token(username, password):\n",
        "    \"\"\"\n",
        "    Obtain an access token to the Copernicus Data Space Ecosystem.\n",
        "    Necessary for the download of hosted products.\n",
        "    \"\"\"\n",
        "    p =  subprocess.run(f\"curl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n",
        "            --header 'Content-Type: application/x-www-form-urlencoded' \\\n",
        "            --data-urlencode 'grant_type=password' \\\n",
        "            --data-urlencode 'username={username}' \\\n",
        "            --data-urlencode 'password={password}' \\\n",
        "            --data-urlencode 'client_id=cdse-public'\", shell=True,capture_output=True, text=True)\n",
        "    access_dict = json.loads(p.stdout)\n",
        "    return access_dict['access_token'], access_dict['refresh_token']\n",
        "\n",
        "#=============================================================================================================================================================#\n",
        "\n",
        "def get_new_access_token(refresh_token):\n",
        "    \"\"\"\n",
        "    Obtain a new access token to the Copernicus Data Space Ecosystem using a previously provided refesh token.\n",
        "    \"\"\"\n",
        "    p =  subprocess.run(f\"curl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n",
        "    --header 'Content-Type: application/x-www-form-urlencoded' \\\n",
        "    --data-urlencode 'grant_type=refresh_token' \\\n",
        "    --data-urlencode 'refresh_token={refresh_token}' \\\n",
        "    --data-urlencode 'client_id=cdse-public'\", shell=True,capture_output=True, text=True)\n",
        "    access_dict = json.loads(p.stdout)\n",
        "    return access_dict['access_token'], access_dict['refresh_token']\n",
        "\n",
        "#=============================================================================================================================================================#\n",
        "\n",
        "def get_S3_SI_search_results_df(date):\n",
        "    \"\"\"\n",
        "    Obtain a pandas dataframe of Sentinel-3 sea ice thematic products for a given date.\n",
        "    \"\"\"\n",
        "    json = requests.get(f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-3' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'SR_2_LAN_SI') and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'timeliness' and att/OData.CSC.StringAttribute/Value eq 'NT') and ContentDate/Start gt {(date-pd.Timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%SZ')} and ContentDate/End lt {(date+pd.Timedelta(days=2)).strftime('%Y-%m-%dT%H:%M:%SZ')}&$top=1000\").json()\n",
        "\n",
        "    results_df = pd.DataFrame.from_dict(json['value'])\n",
        "    results_df['Satellite'] = [row['Name'][:3] for i,row in results_df.iterrows()]\n",
        "    results_df['SensingStart'] = [pd.to_datetime(row['ContentDate']['Start']) for i,row in results_df.iterrows()]\n",
        "    results_df['SensingEnd'] = [pd.to_datetime(row['ContentDate']['End']) for i,row in results_df.iterrows()]\n",
        "    results_df =  results_df[(results_df['SensingEnd'] >= date) & (results_df['SensingStart'] <= date+pd.Timedelta(days=1))]\n",
        "    results_df = results_df.sort_values(by='SensingStart')\n",
        "    return results_df\n",
        "\n",
        "\n",
        "#=============================================================================================================================================================#\n",
        "\n",
        "def filter_duplicate_products_versions(results_df, keep_latest=True ):\n",
        "    \"\"\"\n",
        "    Filter Sentinel-3 product dataframe to remove duplicate verions of files.\n",
        "    By default, we keep the latest version of the file. E.g., where an operation version\n",
        "    and a reprocessed version exists, we keep the reprocessed version.\n",
        "    \"\"\"\n",
        "    results_df['name_snippet'] = [row['Name'][:47] for i,row in results_df.iterrows()]\n",
        "    if  keep_latest == True:\n",
        "        keep='last'\n",
        "    else:\n",
        "        keep = 'first'\n",
        "\n",
        "    results_df = (\n",
        "        results_df\n",
        "        .sort_values(by='ModificationDate')\n",
        "        .drop_duplicates(subset=['name_snippet'], keep=keep)\n",
        "        .drop(columns = ['name_snippet'])\n",
        "        .sort_values(by='SensingStart')\n",
        "    )\n",
        "\n",
        "    return results_df\n",
        "\n",
        "def find_overlapping_sar(olci_filename, search_results_df):\n",
        "    # Extract date and time from OLCI filename\n",
        "    parts = olci_filename.split('_')\n",
        "    olci_date_time = datetime.strptime(parts[7], '%Y%m%dT%H%M%S')\n",
        "\n",
        "    # Filter SAR filenames based on overlapping criteria\n",
        "    # This is a placeholder logic, adjust according to your specific criteria\n",
        "    overlapping_sar = search_results_df[search_results_df['Name'].apply(lambda x: 'S3' in x and 'SR_2_LAN_SI' in x)]\n",
        "\n",
        "    return overlapping_sar\n",
        "\n",
        "\n",
        "def get_date_from_olci_filename(olci_filename):\n",
        "    \"\"\"\n",
        "    Extracts the date from an OLCI filename.\n",
        "\n",
        "    Parameters:\n",
        "    olci_filename (str): The OLCI filename.\n",
        "\n",
        "    Returns:\n",
        "    datetime.date: The date extracted from the filename.\n",
        "    \"\"\"\n",
        "    parts = olci_filename.split('_')\n",
        "    date_str = parts[7][:8]  # Extract date part and truncate to YYYYMMDD format\n",
        "    return pd.to_datetime(date_str, format='%Y%m%d').date()\n",
        "\n",
        "def get_overlapping_sar_file(olci_filename, get_S3_SI_search_results_df, token):\n",
        "    olci_date = get_date_from_olci_filename(olci_filename)\n",
        "    start_date = olci_date - pd.Timedelta(days=1)\n",
        "    end_date = olci_date + pd.Timedelta(days=1)\n",
        "    dates = pd.date_range(start_date, end_date)\n",
        "\n",
        "    all_overlapping_sar = pd.DataFrame()  # Collect all overlapping SAR files\n",
        "\n",
        "    for date in dates:\n",
        "        date = date.tz_localize('UTC')\n",
        "        search_results_df = get_S3_SI_search_results_df(date)\n",
        "\n",
        "        if search_results_df.empty:\n",
        "            print(f\"No SAR data found for date: {date}\")\n",
        "            continue\n",
        "\n",
        "        filtered_df = filter_duplicate_products_versions(search_results_df)\n",
        "        if filtered_df.empty:\n",
        "            print(f\"No SAR data after filtering for date: {date}\")\n",
        "            continue\n",
        "\n",
        "        overlapping_sar = find_overlapping_sar(olci_filename, filtered_df)\n",
        "        if not overlapping_sar.empty:\n",
        "            all_overlapping_sar = pd.concat([all_overlapping_sar, overlapping_sar], ignore_index=True)\n",
        "\n",
        "    return all_overlapping_sar\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def check_overlap(row, olci_filename, olci_start, olci_end):\n",
        "    \"\"\"\n",
        "    Checks if the SAR file's sensing period overlaps with the OLCI file's sensing period and if it's from the same satellite.\n",
        "\n",
        "    Parameters:\n",
        "    row (Series): A row from the SAR search results DataFrame.\n",
        "    olci_filename (str): The OLCI filename.\n",
        "    olci_start (datetime): Start time of OLCI sensing period.\n",
        "    olci_end (datetime): End time of OLCI sensing period.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if there's an overlap and the satellite is consistent, False otherwise.\n",
        "    \"\"\"\n",
        "    # Extract satellite identifier from the OLCI filename\n",
        "    satellite = olci_filename.split('_')[0]  # e.g., S3A or S3B\n",
        "\n",
        "    # Parse SAR start and end times\n",
        "    sar_start = datetime.strptime(row['ContentDate']['Start'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "    sar_end = datetime.strptime(row['ContentDate']['End'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "\n",
        "    # Check for temporal overlap and satellite consistency\n",
        "    is_temporal_overlap = sar_start <= olci_end and sar_end >= olci_start\n",
        "    is_same_satellite = satellite in row['Name']\n",
        "\n",
        "    return is_temporal_overlap and is_same_satellite\n",
        "\n",
        "# Adjust the find_overlapping_sar function to include the OLCI filename in the check_overlap call\n",
        "def find_overlapping_sar(olci_filename, search_results_df):\n",
        "    # Extract date and time from OLCI filename\n",
        "    parts = olci_filename.split('_')\n",
        "    olci_sensing_start = datetime.strptime(parts[7], '%Y%m%dT%H%M%S')\n",
        "    olci_sensing_end = datetime.strptime(parts[8], '%Y%m%dT%H%M%S')\n",
        "\n",
        "    # Filter for SAR files that overlap with the OLCI sensing period\n",
        "    overlapping_sar = search_results_df[search_results_df.apply(lambda row: check_overlap(row, olci_filename, olci_sensing_start, olci_sensing_end), axis=1)]\n",
        "\n",
        "    return overlapping_sar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPbKhR6wOYm9"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "\n",
        "token, refresh_token = get_access_token(username, password)\n",
        "olci_filename = s3_olci_data['Name'][0] # This is an example, which you should replace with the one you are interested in.\n",
        "overlapped_df = get_overlapping_sar_file(olci_filename, get_S3_SI_search_results_df, token)\n",
        "product_id = overlapped_df['Id'].iloc[0]\n",
        "file_name = overlapped_df['Name'].iloc[0]\n",
        "download_dir = '/content/drive/MyDrive/GEOL0069/Week4'\n",
        "download_single_product(product_id, file_name, token, download_dir)\n",
        "\n",
        "# We've now gathered Sentinel-2 optical data, Sentinel-3 OLCI, and altimetry data,\n",
        "# enabling us to advance into a comprehensive analysis leveraging their combined strengths."
      ]
    }
  ]
}